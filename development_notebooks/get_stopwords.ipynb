{
 "metadata": {
  "name": "",
  "signature": "sha256:0e0579539d5dd831110c4865e2162a5b3a87d11285c240b83e0c085cd5c377db"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlalchemy as sa\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.snowball import SnowballStemmer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db_engine = sa.create_engine(\"mysql+pymysql://will:melody11@192.168.1.200/tweet_harvester?charset=utf8mb4&use_unicode=True\", encoding=\"utf8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# upload some stopwords (1 off)\n",
      "stopwords_df = pd.DataFrame(stopwords.words('english'), columns=['stopword'])\n",
      "stopwords_df['language'] = 'en'\n",
      "stopwords_df['stopword_id'] = stopwords_df.index + 1\n",
      "stemmer = SnowballStemmer(\"english\")\n",
      "\n",
      "stopwords_df['word_stemmed'] = stopwords_df['stopword'].apply(stemmer.stem)\n",
      "stopwords_df.to_sql('stopword', db_engine, if_exists='append', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 664
    }
   ],
   "metadata": {}
  }
 ]
}